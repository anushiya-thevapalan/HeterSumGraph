{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anushiya/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import random\n",
    "\n",
    "import dgl\n",
    "import numpy as np\n",
    "import torch\n",
    "from rouge import Rouge\n",
    "\n",
    "from HiGraph import HSumGraph, HSumDocGraph\n",
    "from Tester import SLTester\n",
    "from module.dataloader import ExampleSet, MultiExampleSet, graph_collate_fn\n",
    "from module.embedding import Word_Embedding\n",
    "from module.vocabulary import Vocab\n",
    "from tools.logger import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model from checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"checkpoints/multinews.ckpt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python evaluation.py --data_dir datasets/multinews --cache_dir cache/MultiNews --embedding_path glove/glove.6B.100d.txt --model HDSG --save_root save/ --log_root log/ -m 3 --test_model multi --use_pyrouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-06 16:42:03,449 INFO    : Pytorch 1.12.0\n",
      "2024-09-06 16:42:03,451 INFO    : [INFO] Create Vocab, vocab path is cache/MultiNews/vocab\n",
      "2024-09-06 16:42:03,488 INFO    : [INFO] max_size of vocab was specified as 50000; we now have 50000 words. Stopping reading.\n",
      "2024-09-06 16:42:03,489 INFO    : [INFO] Finished constructing vocabulary of 50000 total words. Last word added: medicated\n",
      "2024-09-06 16:42:03,658 INFO    : [INFO] Loading external word embedding...\n",
      "2024-09-06 16:43:23,395 INFO    : [INFO] External Word Embedding iov count: 48908, oov count: 1092\n"
     ]
    }
   ],
   "source": [
    "args = argparse.Namespace(\n",
    "    data_dir='datasets/multinews',\n",
    "    cache_dir='cache/MultiNews',\n",
    "    embedding_path='glove/glove.42B.300d.txt',\n",
    "    model=\"HDSG\",\n",
    "    test_model='evalbestmodel',\n",
    "    use_pyrouge=False,\n",
    "    save_root='save/',\n",
    "    log_root='log/',\n",
    "    gpu='0',\n",
    "    cuda=False,\n",
    "    vocab_size=50000,\n",
    "    batch_size=32,\n",
    "    n_iter=1,\n",
    "    word_embedding=True,\n",
    "    word_emb_dim=300,\n",
    "    embed_train=False,\n",
    "    feat_embed_size=50,\n",
    "    n_layers=1,\n",
    "    lstm_hidden_state=128,\n",
    "    lstm_layers=2,\n",
    "    bidirectional=True,\n",
    "    n_feature_size=128,\n",
    "    hidden_size=64,\n",
    "    gcn_hidden_size=128,\n",
    "    ffn_inner_hidden_size=512,\n",
    "    n_head=8,\n",
    "    recurrent_dropout_prob=0.1,\n",
    "    atten_dropout_prob=0.1,\n",
    "    ffn_dropout_prob=0.1,\n",
    "    use_orthnormal_init=True,\n",
    "    sent_max_len=100,\n",
    "    doc_max_timesteps=50,\n",
    "    save_label=False,\n",
    "    limited=False,\n",
    "    blocking=False,\n",
    "    m=3\n",
    ")\n",
    "\n",
    "# File paths\n",
    "DATA_FILE = os.path.join(args.data_dir, \"test.label.jsonl\")\n",
    "VOCAL_FILE = os.path.join(args.cache_dir, \"vocab\")\n",
    "FILTER_WORD = os.path.join(args.cache_dir, \"filter_word.txt\")\n",
    "LOG_PATH = args.log_root\n",
    "\n",
    "logger.info(\"Pytorch %s\", torch.__version__)\n",
    "logger.info(\"[INFO] Create Vocab, vocab path is %s\", VOCAL_FILE)\n",
    "vocab = Vocab(VOCAL_FILE, args.vocab_size)\n",
    "embed = torch.nn.Embedding(vocab.size(), args.word_emb_dim)\n",
    "if args.word_embedding:\n",
    "    embed_loader = Word_Embedding(args.embedding_path, vocab)\n",
    "    vectors = embed_loader.load_my_vecs(args.word_emb_dim)\n",
    "    pretrained_weight = embed_loader.add_unknown_words_by_avg(vectors, args.word_emb_dim)\n",
    "    embed.weight.data.copy_(torch.Tensor(pretrained_weight))\n",
    "    embed.weight.requires_grad = args.embed_train\n",
    "\n",
    "hps = args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HSumDocGraph(hps,embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the checkpoint\n",
    "checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))  # or 'cuda' if using GPU\n",
    "model.load_state_dict(checkpoint)  # Load model state from the checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, save_file):\n",
    "    with open(save_file, 'wb') as f:\n",
    "        torch.save(model.state_dict(), f)\n",
    "    logger.info('[INFO] Saving model to %s', save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-06 16:57:49,153 INFO    : [INFO] Saving model to save/eval/bestmodel_0\n",
      "2024-09-06 16:57:49,197 INFO    : [INFO] Saving model to save/eval/bestmodel_1\n",
      "2024-09-06 16:57:49,241 INFO    : [INFO] Saving model to save/eval/bestmodel_2\n"
     ]
    }
   ],
   "source": [
    "eval_dir = \"save/eval/\"\n",
    "\n",
    "for i in range(3):  \n",
    "    save_file = os.path.join(eval_dir, f\"bestmodel_{i}\")\n",
    "    save_model(model, save_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heter-long-sum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
